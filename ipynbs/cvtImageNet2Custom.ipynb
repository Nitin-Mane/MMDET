{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import warnings\n",
    "import xml.dom.minidom as minidom\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import json\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagenetHome = '../data/imagenet'\n",
    "devkit_path = osp.join(imagenetHome,'devkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synsets_image = sio.loadmat(os.path.join(devkit_path, 'data', 'meta_det.mat'))\n",
    "synsets_video = sio.loadmat(os.path.join(devkit_path, 'data', 'meta_vid.mat'))\n",
    "classes_image = ('__background__',)\n",
    "wnid_image = (0,)\n",
    "classes = ('__background__',)\n",
    "wnid = (0,)\n",
    "for i in range(200):\n",
    "    classes_image = classes_image + (synsets_image['synsets'][0][i][2][0],)\n",
    "    wnid_image = wnid_image + (synsets_image['synsets'][0][i][1][0],)\n",
    "\n",
    "for i in range(30):\n",
    "    classes = classes + (synsets_video['synsets'][0][i][2][0],)\n",
    "    wnid = wnid + (synsets_video['synsets'][0][i][1][0],)\n",
    "\n",
    "wnid_to_ind_image = dict(zip(wnid_image, range(201)))\n",
    "class_to_ind_image = dict(zip(classes_image, range(201)))\n",
    "\n",
    "wnid_to_ind = dict(zip(wnid, range(31)))\n",
    "class_to_ind = dict(zip(classes, range(31)))\n",
    "\n",
    "#check for valid intersection between video and image classes\n",
    "valid_image_flag = [0]*201\n",
    "\n",
    "for i in range(1,201):\n",
    "    if wnid_image[i] in wnid_to_ind:\n",
    "        valid_image_flag[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_tag(node, tag):\n",
    "    return node.getElementsByTagName(tag)[0].childNodes[0].data\n",
    "def has_tag(node, tag):\n",
    "    return node.getElementsByTagName(tag).length>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseImagenetAnnObject(objs, imgSize=None, has_trackid=False):\n",
    "    num_objs = len(objs)\n",
    "    if imgSize is not None:\n",
    "        width, height = imgSize\n",
    "    boxes = np.zeros((num_objs, 4), dtype=np.float32)\n",
    "    gt_classes = np.zeros((num_objs), dtype=np.int64)\n",
    "    if has_trackid:\n",
    "        track_ids = np.zeros((num_objs), dtype=np.int64)\n",
    "        \n",
    "    # Load object bounding boxes into a data frame.\n",
    "    for ix, obj in enumerate(objs):\n",
    "        x1 = max(float(get_data_from_tag(obj, 'xmin')),0)\n",
    "        y1 = max(float(get_data_from_tag(obj, 'ymin')),0)\n",
    "        x2 = max(float(get_data_from_tag(obj, 'xmax')),0)\n",
    "        y2 = max(float(get_data_from_tag(obj, 'ymax')),0)\n",
    "        if imgSize is not None:\n",
    "            # if image size is known, box bound can be trimmed.\n",
    "            x1 = min(x1, width -1)\n",
    "            y1 = min(y1, height-1)\n",
    "            x2 = min(x2, width -1)\n",
    "            y2 = min(y2, height-1)\n",
    "        \n",
    "        cls = wnid_to_ind[str(get_data_from_tag(obj, \"name\")).lower().strip()]\n",
    "        boxes[ix, :] = [x1, y1, x2, y2]\n",
    "        gt_classes[ix] = cls\n",
    "        if has_trackid:\n",
    "            track_ids[ix] = int(get_data_from_tag(obj, 'trackid'))\n",
    "    \n",
    "    if has_trackid is False:\n",
    "        return {'bboxes':boxes.tolist(),\n",
    "                'labels':gt_classes.tolist(),}\n",
    "    else:\n",
    "        return {'bboxes':boxes.tolist(),\n",
    "                'labels':gt_classes.tolist(),\n",
    "                'trackids':track_ids.tolist(),}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_annotation(index_image, img_prefix):\n",
    "    \"\"\"\n",
    "    Load image and bounding boxes info from txt files of imagenet.\n",
    "    \"\"\"\n",
    "    # Get image infos\n",
    "    filename = osp.join(img_prefix, index_image)\n",
    "    assert os.path.exists(filename),'%s'%(filename)\n",
    "    with Image.open(filename) as img:\n",
    "        imgSize = img.size\n",
    "    \n",
    "    # Get ann infos\n",
    "    filename = osp.join(img_prefix, index_image).replace('Data','Annotations').replace('.JPEG','.xml')\n",
    "    index = filename\n",
    "    assert os.path.exists(filename),'%s'%(filename)\n",
    "    with open(filename) as f:\n",
    "        data = minidom.parseString(f.read())\n",
    "\n",
    "    objs = data.getElementsByTagName('object')\n",
    "    num_objs = len(objs)\n",
    "    #filter the objects not in video synsets.\n",
    "    used_objs = []\n",
    "    for id, obj in enumerate(objs):\n",
    "        if str(get_data_from_tag(obj, \"name\")).lower().strip() in wnid_to_ind:\n",
    "            used_objs.append(obj)\n",
    "    objs = used_objs\n",
    "    if len(objs)>0 and has_tag(objs[0],'trackid'):\n",
    "        ann = parseImagenetAnnObject(objs,imgSize=img.size,has_trackid=True)\n",
    "    else:\n",
    "        ann = parseImagenetAnnObject(objs,imgSize=img.size,has_trackid=False)\n",
    "    return {\n",
    "            'filename':index_image,\n",
    "            'width':img.size[0],\n",
    "            'height':img.size[1],\n",
    "            'ann': ann\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCustomAnnByImagenetIndex(index,img_prefix):\n",
    "    '''\n",
    "    Annotation format:\n",
    "    [\n",
    "        {\n",
    "            'filename': 'a.jpg',\n",
    "            'width': 1280,\n",
    "            'height': 720,\n",
    "            'ann': {\n",
    "                'bboxes': <np.ndarray> (n, 4),\n",
    "                'labels': <np.ndarray> (n, ),\n",
    "                'bboxes_ignore': <np.ndarray> (k, 4),\n",
    "                'labels_ignore': <np.ndarray> (k, 4) (optional field)\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        index(str): relative file path.\n",
    "        \n",
    "    '''\n",
    "    return load_imagenet_annotation(index,img_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImagenetDETVIDSet2CustomAnn(imageDataPrefix, imagesetPath, cumstomStyleAnnPath):\n",
    "    '''Convert Imagenet DETVID annotations to custom style annotations.\n",
    "    \n",
    "       The imagenet dataset is configured by 1 txt file in \"ImageSets\"\n",
    "       directory(contain image index), while custom style annotations \n",
    "       have all anns in 1 file.\n",
    "       \n",
    "    Args:\n",
    "        imagesetPath(str): imagenet imageset path.\n",
    "        cumstomStyleAnnPath(str): the path to save annotations.\n",
    "    '''\n",
    "    assert cumstomStyleAnnPath.endswith('.json')\n",
    "    file_indexes = []\n",
    "    with open(imagesetPath,'r') as fr:\n",
    "        lines = fr.readlines()\n",
    "        for l in lines:\n",
    "            items = l.split()\n",
    "            file_indexes.append(items[0].replace('data/imagenet/ILSVRC/','')+'.JPEG')\n",
    "    print('total number of files are %d.'%(len(file_indexes)))\n",
    "    \n",
    "    ann_list = []\n",
    "    for i in tqdm(range(len(file_indexes))):\n",
    "        index = file_indexes[i]\n",
    "        ann_dict = getCustomAnnByImagenetIndex(index,imageDataPrefix)\n",
    "        ann_list.append(ann_dict)\n",
    "        \n",
    "    with open(cumstomStyleAnnPath,'w') as fw:\n",
    "        json.dump(ann_list, fw, indent=2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImagenetVIDSet2CustomDETAnn(imageDataPrefix, imagesetPath, cumstomStyleAnnPath):\n",
    "    assert cumstomStyleAnnPath.endswith('.json')\n",
    "    file_indexes = []\n",
    "    with open(imagesetPath,'r') as fr:\n",
    "        lines = fr.readlines()\n",
    "        for l in lines:\n",
    "            items = l.split()\n",
    "            file_indexes.append(items[0]+'.JPEG')\n",
    "    print('total number of files are %d.'%(len(file_indexes)))\n",
    "    \n",
    "    ann_list = []\n",
    "    for i in tqdm(range(len(file_indexes))):\n",
    "        index = file_indexes[i]\n",
    "        ann_dict = getCustomAnnByImagenetIndex(index,imageDataPrefix)\n",
    "        ann_list.append(ann_dict)\n",
    "        \n",
    "    with open(cumstomStyleAnnPath,'w') as fw:\n",
    "        json.dump(ann_list, fw, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_DETVID_train():\n",
    "    imagesetPath = '/media/yelyu/18339a64-762e-4258-a609-c0851cd8163e/YeLyu/Work/FastVOD/data/imagenet/ILSVRC/ImageSets/trainr_DETVID.txt'\n",
    "    cumstomStyleAnnPath = imagesetPath.replace('.txt','.json')\n",
    "    ImagenetDETVIDSet2CustomAnn(imagenetHome, imagesetPath,cumstomStyleAnnPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_VID_val():\n",
    "    imagesetPath = '/media/yelyu/18339a64-762e-4258-a609-c0851cd8163e/YeLyu/Work/FastVOD/data/imagenet/ILSVRC/ImageSets/VID_val.txt'\n",
    "    cumstomStyleAnnPath = imagesetPath.replace('.txt','.json')\n",
    "    ImagenetVIDSet2CustomDETAnn(osp.join(imagenetHome,'Data/VID/val'), imagesetPath,cumstomStyleAnnPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/176126 [00:00<10:58, 267.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of files are 176126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176126/176126 [15:42<00:00, 298.05it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main_VID_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
